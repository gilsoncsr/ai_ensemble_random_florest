# üîç Employee Churn Prediction

This project aims to analyze and predict **employee churn** based on historical company data. By applying data science techniques, feature engineering, machine learning, and cross-validation, the project seeks to identify patterns that contribute to employee turnover and assist in making strategic retention decisions.

---

## üß† Technologies Used

- **Language:** Python 3.11+
- **Data Analysis and Visualization:** Pandas, NumPy, Matplotlib, Plotly, Scipy
- **Preprocessing:** Scikit-learn (ColumnTransformer, StandardScaler, OneHotEncoder)
- **Modeling:** RandomForestClassifier
- **Validation and Optimization:** GridSearchCV, StratifiedKFold, Optuna
- **Explainability:** SHAP
- **Virtual Environment:** Pipenv

---

## üìÅ Project Structure

- `datasets/employees_churn_dataset.csv` ‚Äî Employee dataset
- `main.ipynb` ‚Äî Main notebook containing the entire analysis, feature engineering, modeling, and evaluation pipeline
- `README.md` ‚Äî General project description

---

## üìä Steps Performed

### 1. **Data Exploration and Cleaning**

- Reading the dataset with proper date handling
- Null value and data structure analysis
- Visualizations using Plotly (boxplots, histograms, scatter matrix)

### 2. **Feature Engineering**

- Calculation of company tenure, time since last feedback/raise/promotion
- Removal of irrelevant columns (e.g., ID)

### 3. **Exploratory Data Analysis (EDA)**

- Churn distribution
- Statistical tests (Chi-Square) between categorical variables and churn
- Correlation matrix for numerical variables

### 4. **Modeling Preparation**

- Splitting features (`X`) and target (`y`)
- Dropping datetime and irrelevant columns
- Preprocessing with `StandardScaler` and `OneHotEncoder`
- Splitting data into training and testing sets (50% each)

### 5. **Modeling**

- Training a baseline Random Forest model
- Evaluation using metrics such as AUC, F1-score, precision, and recall
- ROC curve and confusion matrix visualization

### 6. **Cross-Validation + Hyperparameter Tuning**

- Applying `GridSearchCV` with `StratifiedKFold` (5 folds)
- Tuning parameters like `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`
- Returning the best model, best parameters, and recall metric

---

## üß™ Results

- **AUC ROC:** ~0.89
- **Optimized Recall:** after cross-validation
- **Feature Importance:** interpreted with SHAP (in progress)

---

## üõ† How to Run

```bash
# Clone the repository

# Install Pipenv (if not already installed)
pip install pipenv

# Create the virtual environment and install dependencies
pipenv install pandas scipy plotly scikit-learn optuna shap ipykernel ipywidgets nbformat numpy

# Activate the virtual environment
pipenv shell

# Open the notebook in Jupyter
jupyter notebook main.ipynb
```

---

# üîç Predicci√≥n de Rotaci√≥n de Empleados

Este proyecto tiene como objetivo analizar y predecir la **rotaci√≥n de empleados** a partir de datos hist√≥ricos de la empresa. Aplicando t√©cnicas de ciencia de datos, ingenier√≠a de caracter√≠sticas, aprendizaje autom√°tico y validaci√≥n cruzada, el proyecto busca identificar patrones que contribuyen a la salida de empleados y ayudar en la toma de decisiones estrat√©gicas de retenci√≥n.

---

## üß† Tecnolog√≠as Utilizadas

- **Lenguaje:** Python 3.11+
- **An√°lisis y Visualizaci√≥n de Datos:** Pandas, NumPy, Matplotlib, Plotly, Scipy
- **Preprocesamiento:** Scikit-learn (ColumnTransformer, StandardScaler, OneHotEncoder)
- **Modelado:** RandomForestClassifier
- **Validaci√≥n y Optimizaci√≥n:** GridSearchCV, StratifiedKFold, Optuna
- **Interpretabilidad:** SHAP
- **Entorno Virtual:** Pipenv

---

## üìÅ Estructura del Proyecto

- `datasets/employees_churn_dataset.csv` ‚Äî Conjunto de datos de empleados
- `main.ipynb` ‚Äî Notebook principal con todo el pipeline de an√°lisis, ingenier√≠a de caracter√≠sticas, modelado y evaluaci√≥n
- `README.md` ‚Äî Descripci√≥n general del proyecto

---

## üìä Etapas Realizadas

### 1. **Exploraci√≥n y Limpieza de Datos**

- Lectura del conjunto de datos con manejo adecuado de fechas
- An√°lisis de valores nulos y estructura de los datos
- Visualizaciones con Plotly (diagramas de caja, histogramas, matriz de dispersi√≥n)

### 2. **Ingenier√≠a de Caracter√≠sticas**

- C√°lculo del tiempo en la empresa, tiempo desde el √∫ltimo feedback/aumento/promoci√≥n
- Eliminaci√≥n de columnas irrelevantes (como el ID)

### 3. **An√°lisis Exploratorio de Datos (EDA)**

- Distribuci√≥n de la rotaci√≥n
- Pruebas estad√≠sticas (Chi-cuadrado) entre variables categ√≥ricas y la rotaci√≥n
- Matriz de correlaci√≥n para variables num√©ricas

### 4. **Preparaci√≥n para el Modelado**

- Separaci√≥n entre caracter√≠sticas (`X`) y objetivo (`y`)
- Eliminaci√≥n de columnas de tipo datetime e irrelevantes
- Preprocesamiento con `StandardScaler` y `OneHotEncoder`
- Divisi√≥n de los datos en entrenamiento y prueba (50% cada uno)

### 5. **Modelado**

- Entrenamiento de un modelo base con Random Forest
- Evaluaci√≥n con m√©tricas como AUC, F1-score, precisi√≥n y recall
- Visualizaci√≥n de la curva ROC y matriz de confusi√≥n

### 6. **Validaci√≥n Cruzada + Ajuste de Hiperpar√°metros**

- Aplicaci√≥n de `GridSearchCV` con `StratifiedKFold` (5 particiones)
- Optimizaci√≥n de par√°metros como `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`
- Retorno del mejor modelo, mejores par√°metros y m√©trica de recall

---

## üß™ Resultados

- **AUC ROC:** ~0.89
- **Recall Optimizado:** tras validaci√≥n cruzada
- **Importancia de Caracter√≠sticas:** interpretada con SHAP (en desarrollo)

---

## üõ† C√≥mo Ejecutar

```bash
# Clonar el repositorio

# Instalar Pipenv (si a√∫n no est√° instalado)
pip install pipenv

# Crear el entorno virtual e instalar las dependencias
pipenv install pandas scipy plotly scikit-learn optuna shap ipykernel ipywidgets nbformat numpy

# Activar el entorno virtual
pipenv shell

# Abrir el notebook en Jupyter
jupyter notebook main.ipynb
```

---

# üîç Employee Churn Prediction

Este projeto tem como objetivo analisar e prever o **Churn (rotatividade)** de funcion√°rios com base em dados hist√≥ricos da empresa. Utilizando t√©cnicas de ci√™ncia de dados, engenharia de features, aprendizado de m√°quina e valida√ß√£o cruzada, o projeto busca identificar padr√µes que contribuam para a sa√≠da de colaboradores e auxiliar na tomada de decis√µes estrat√©gicas de reten√ß√£o.

---

## üß† Tecnologias Utilizadas

- **Linguagem:** Python 3.11+
- **An√°lise e Visualiza√ß√£o de Dados:** Pandas, NumPy, Matplotlib, Plotly, Scipy
- **Pr√©-processamento:** Scikit-learn (ColumnTransformer, StandardScaler, OneHotEncoder)
- **Modelagem:** RandomForestClassifier
- **Valida√ß√£o e Otimiza√ß√£o:** GridSearchCV, StratifiedKFold, Optuna
- **Explicabilidade:** SHAP
- **Ambiente Virtual:** Pipenv

---

## üìÅ Estrutura do Projeto

- `datasets/employees_churn_dataset.csv` ‚Äî Base de dados de funcion√°rios
- `main.ipynb` ‚Äî C√≥digo principal com todo o pipeline de an√°lise, engenharia de features, modelagem e avalia√ß√£o
- `README.md` ‚Äî Descri√ß√£o geral do projeto

---

## üìä Etapas Realizadas

### 1. **Explora√ß√£o e Limpeza dos Dados**

- Leitura da base com tratamento de datas
- An√°lise de valores nulos e estrutura dos dados
- Visualiza√ß√µes com Plotly (boxplots, histogramas, matriz de dispers√£o)

### 2. **Engenharia de Atributos**

- C√°lculo de tempo de empresa, tempo desde √∫ltimo feedback/aumento/mudan√ßa de cargo
- Exclus√£o de colunas irrelevantes (como ID)

### 3. **An√°lise Explorat√≥ria (EDA)**

- Distribui√ß√£o do churn
- Testes estat√≠sticos (Qui-Quadrado) entre vari√°veis categ√≥ricas e o churn
- Matriz de correla√ß√£o para vari√°veis num√©ricas

### 4. **Prepara√ß√£o para Modelagem**

- Separa√ß√£o entre features (`X`) e target (`y`)
- Exclus√£o de colunas datetime e vari√°veis irrelevantes
- Pr√©-processamento com `StandardScaler` e `OneHotEncoder`
- Separa√ß√£o em treino e teste (50% cada)

### 5. **Modelagem**

- Treinamento de um modelo base com Random Forest
- Avalia√ß√£o com m√©tricas como AUC, F1-score, precision, recall
- Visualiza√ß√£o da curva ROC e matriz de confus√£o

### 6. **Valida√ß√£o Cruzada + Tuning de Hiperpar√¢metros**

- Aplica√ß√£o de `GridSearchCV` com `StratifiedKFold` (5 folds)
- Otimiza√ß√£o de par√¢metros como `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`
- Retorno do melhor modelo, melhores par√¢metros e m√©trica de recall

---

## üß™ Resultados

- **AUC ROC:** ~0.89
- **Recall Otimizado:** ap√≥s valida√ß√£o cruzada
- **Import√¢ncia de Features:** interpretadas com SHAP (em desenvolvimento)

---

## üõ† Como Executar

```bash
# Clone o reposit√≥rio

# Instale o Pipenv (se ainda n√£o tiver)
pip install pipenv

# Crie o ambiente virtual e instale as depend√™ncias
pipenv install pandas scipy plotly scikit-learn optuna shap ipykernel ipywidgets nbformat numpy

# Ative o ambiente virtual
pipenv shell

# Abra o notebook no Jupyter
jupyter notebook main.ipynb
```
